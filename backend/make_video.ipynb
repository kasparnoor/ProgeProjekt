{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e09e71bc-d4d6-486c-aa59-1ce7045dc978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: python-pptx in /home/kaur/.local/lib/python3.8/site-packages (0.6.23)\n",
      "Requirement already satisfied: lxml>=3.1.0 in /home/kaur/.local/lib/python3.8/site-packages (from python-pptx) (5.2.1)\n",
      "Requirement already satisfied: Pillow>=3.3.2 in /home/kaur/.local/lib/python3.8/site-packages (from python-pptx) (9.5.0)\n",
      "Requirement already satisfied: XlsxWriter>=0.5.7 in /usr/local/lib/python3.8/dist-packages (from python-pptx) (3.2.0)\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.8.3 has a non-standard dependency specifier torch>=1.9.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mG4_Rannaprotsesid_2024.pptx\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "!pip install python-pptx\n",
    "from pptx import Presentation\n",
    "import glob\n",
    "\n",
    "for eachfile in glob.glob(\"*.pptx\"):\n",
    "    prs = Presentation(eachfile)\n",
    "    print(eachfile)\n",
    "    print(\"----------------------\")\n",
    "    slide_number = 1\n",
    "    for slide in prs.slides:\n",
    "        for shape in slide.shapes:\n",
    "            if hasattr(shape, \"text\"):\n",
    "                with open(f'video_tekstid/slide_{slide_number}_text.txt', 'w') as st:\n",
    "                    st.write(shape.text)\n",
    "                slide_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfc33763-4690-4d43-b4bd-c566a8ff78e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-03 20:00:33.605644: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-03 20:00:34.520324: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/kaur/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AE working on z of shape (1, 4, 64, 64) = 16384 dimensions.\n",
      ">>> model checkpoint loaded.\n",
      "start: random men kising blue red green 2024-06-03 20:00:57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaur/.local/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py:120: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No CUDA GPUs are available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m eta \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m     22\u001b[0m fps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m\n\u001b[0;32m---> 24\u001b[0m generated_videos \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_videos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, video \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(generated_videos):\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerated video \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m saved at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvideo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m, in \u001b[0;36mgenerate_videos\u001b[0;34m(prompts, steps, cfg_scale, eta, fps, result_dir)\u001b[0m\n\u001b[1;32m      8\u001b[0m videos \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[0;32m---> 10\u001b[0m     video \u001b[38;5;241m=\u001b[39m \u001b[43mtext2video\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     videos\u001b[38;5;241m.\u001b[39mappend(video)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m videos\n",
      "File \u001b[0;32m~/projects/VideoCrafter/scripts/gradio/t2v_test.py:48\u001b[0m, in \u001b[0;36mText2Video.get_prompt\u001b[0;34m(self, prompt, steps, cfg_scale, eta, fps)\u001b[0m\n\u001b[1;32m     45\u001b[0m     steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m60\u001b[39m\n\u001b[1;32m     47\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_list[gpu_id]\n\u001b[0;32m---> 48\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# Reduce batch size to manage memory usage\u001b[39;00m\n\u001b[1;32m     50\u001b[0m channels \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdiffusion_model\u001b[38;5;241m.\u001b[39min_channels\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/lightning_lite/utilities/device_dtype_mixin.py:69\u001b[0m, in \u001b[0;36m_DeviceDtypeModuleMixin.cuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Moves all model parameters and buffers to the GPU. This also makes associated parameters and buffers\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03mdifferent objects. So it should be called before constructing optimizer if the module will live on GPU\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03mwhile being optimized.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m    Module: self\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 69\u001b[0m     device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m     71\u001b[0m     device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:674\u001b[0m, in \u001b[0;36mcurrent_device\u001b[0;34m()\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcurrent_device\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m    673\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the index of a currently selected device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_cuda_getDevice()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:247\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    246\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 247\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    251\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from scripts.gradio.t2v_test import Text2Video\n",
    "sys.path.insert(1, os.path.join(sys.path[0], 'lvdm'))\n",
    "\n",
    "def generate_videos(prompts, steps, cfg_scale, eta, fps, result_dir='./tmp/'):\n",
    "    text2video = Text2Video(result_dir)\n",
    "    videos = []\n",
    "    for prompt in prompts:\n",
    "        video = text2video.get_prompt(prompt, steps, cfg_scale, eta, fps)\n",
    "        videos.append(video)\n",
    "    return videos\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    result_dir = os.path.join('./', 'results')\n",
    "    \n",
    "    # Define your parameters here\n",
    "    prompts = ['random men kising blue red green']\n",
    "    steps = 50\n",
    "    cfg_scale = 12\n",
    "    eta = 1.0\n",
    "    fps = 16\n",
    "    \n",
    "    generated_videos = generate_videos(prompts, steps, cfg_scale, eta, fps, result_dir)\n",
    "    \n",
    "    for idx, video in enumerate(generated_videos):\n",
    "        print(f\"Generated video {idx+1} saved at: {video}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8efda78-0694-4475-aec6-d03ea03a37b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.gradio.t2v_test import Text2Video\n",
    "\n",
    "\n",
    "def videocrafter_demo(result_dir='./tmp/'):\n",
    "    text2video = Text2Video(result_dir)\n",
    "        input_text_list = vt.readlines()\n",
    "        input_text = ''.join(input_text_list)\n",
    "        #print(type(input_text))\n",
    "        steps = 10\n",
    "        cfg_scale = 12.0\n",
    "        eta = 1.0\n",
    "        fps = 5\n",
    "    \n",
    "    # Assuming there are functions to get input and output video\n",
    "    \n",
    "    text2video.get_prompt(input_text, steps, cfg_scale, eta, fps)\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a82d6c35-a703-49a7-aeed-b9f7ef2e5535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AE working on z of shape (1, 4, 64, 64) = 16384 dimensions.\n",
      ">>> model checkpoint loaded.\n",
      "start: Võsu rand kasvab kinni – hääbuv rand 2024-05-17 19:24:42\n",
      "DDIM scale True\n",
      "ddim device cuda:0\n",
      "Saved in Võsu_rand_kasvab_kinni_–_hääbu. Time used: 37.23 seconds\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(videocrafter_demo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "172f5bcf-354e-4672-9226-ed0b95fb03ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: nvidea-smi: command not found\n"
     ]
    }
   ],
   "source": [
    "!nvidea-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4681bfdf-7e5c-4f5f-8f43-c7074acfee1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kaur/projects/VideoCrafter\n"
     ]
    }
   ],
   "source": [
    "!pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9da72d-9ca2-48c2-b9bf-11388e5fb507",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
